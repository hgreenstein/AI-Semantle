{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bisect \n",
    "import math\n",
    "import random\n",
    "import gensim\n",
    "from constants import PATH_TO_DATASET\n",
    "from answers import secretWords as answers\n",
    "from secondLevelClusters import secondLevelClusters\n",
    "import queue\n",
    "import heuristicrnn\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "gnews_model = gensim.models.KeyedVectors.load_word2vec_format(PATH_TO_DATASET, binary=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Environment:\n",
    "    MAX_NUM_PREV_BIN_SCORES = 4\n",
    "    ALPHA = 0.2\n",
    "    def __init__(self, mystery_word, clusters):\n",
    "        \"\"\"\n",
    "        Initialize the game environment.\n",
    "\n",
    "        Parameters:\n",
    "        - mystery_word: the word to be guessed\n",
    "        - clusters: a list of clusters for the game state space\n",
    "        \"\"\"\n",
    "        self.mystery_word = mystery_word\n",
    "        self.clusters = clusters\n",
    "        self.sub_clusters = secondLevelClusters\n",
    "        sub_clusters = secondLevelClusters\n",
    "        self.guessed_words = []\n",
    "        self.state = [0] * len(clusters)\n",
    "        self.previous_state = [0] * len(clusters)\n",
    "        self.sub_state = [[0] * len(sub_clusters[i]) for i in range(len(clusters))]  # New line\n",
    "        self.previous_sub_state = [[0] * len(sub_clusters[i]) for i in range(len(clusters))]  # New line\n",
    "        self.previous_binned_scores = [[]] * len(clusters)\n",
    "        self.previous_sub_binned_scores = [[[] for _ in sub_clusters[i]] for i in range(len(clusters))]  # New line\n",
    "        #self.weights = calculate_weights(self.MAX_NUM_PREV_BIN_SCORES, self.ALPHA)\n",
    "        \n",
    "    def bin_similarity_score(self, similarity_score):\n",
    "        \"\"\"\n",
    "        Assign a similarity score to one of four bins based on its value.\n",
    "\n",
    "        Parameters:\n",
    "        - similarity_score: the similarity score between a guessed word and the mystery word\n",
    "\n",
    "        Returns:\n",
    "        - the index of the bin for the similarity score\n",
    "        \"\"\"\n",
    "        bins = [0, 15, 25, 50]\n",
    "        return bisect.bisect_left(bins, similarity_score)\n",
    "    def add_score_to_history(self, cluster_number, binned_score):\n",
    "        \"\"\"\n",
    "        Add a binned score of a certain cluster number to its previous binned\n",
    "        scores, and remove the least recent score if the list is too long.\n",
    "        \"\"\"\n",
    "        self.previous_binned_scores[cluster_number].append(binned_score)\n",
    "        if len(self.previous_binned_scores[cluster_number]) > self.MAX_NUM_PREV_BIN_SCORES:\n",
    "            self.previous_binned_scores[cluster_number].pop(0)\n",
    "\n",
    "    def get_state_from_weighted_sum(self, cluster_number):\n",
    "        \"\"\"\n",
    "        Get the weighted score of the previous scores of the specified cluster.\n",
    "        \"\"\"\n",
    "        prev_binned_scores = self.previous_binned_scores[cluster_number].copy()\n",
    "\n",
    "        weights = self.weights if len(prev_binned_scores) == self.MAX_NUM_PREV_BIN_SCORES \\\n",
    "                    else calculate_weights(len(prev_binned_scores), self.ALPHA)\n",
    "        \n",
    "        res_array = [prev_binned_scores[i] * weights[i] \\\n",
    "                     for i in range(len(prev_binned_scores))]\n",
    "        \n",
    "        return (int)(round(sum(res_array)))\n",
    "\n",
    "    def guess_word(self, word, top_action, sub_action):\n",
    "        \"\"\"\n",
    "        Guess a word and update the game state and guessed words accordingly.\n",
    "\n",
    "        Parameters:\n",
    "        - word: the word to guess\n",
    "        - top_action: the index of the top-level cluster for the guessed word\n",
    "        - sub_action: the index of the sub-level cluster for the guessed word\n",
    "\n",
    "        Returns:\n",
    "        - the similarity score between the guessed word and the mystery word\n",
    "        \"\"\"\n",
    "        if word in [gw[0] for gw in self.guessed_words]:\n",
    "            return -100\n",
    "\n",
    "        if word == self.mystery_word:\n",
    "            return 100\n",
    "\n",
    "        similarity_score = round(100 * gnews_model.similarity(word, self.mystery_word), 6)\n",
    "        self.guessed_words.append((word, similarity_score))\n",
    "        self.guessed_words = sorted(self.guessed_words, key=lambda x: x[1], reverse=True)\n",
    "        binned_score = self.bin_similarity_score(similarity_score)\n",
    "        self.previous_state = self.state.copy()\n",
    "        self.previous_sub_state[top_action] = self.sub_state[top_action].copy()  \n",
    "        self.state[top_action] = binned_score\n",
    "        self.sub_state[top_action][sub_action] = binned_score\n",
    "        return similarity_score\n",
    "\n",
    "    # def get_reward(self, similarity_score, num_guesses, max_guesses, guess):\n",
    "    #     \"\"\"\n",
    "    #     Calculate the reward for the current game state and action.\n",
    "\n",
    "    #     Parameters:\n",
    "    #     - similarity_score: the similarity score between the guessed word and the mystery word\n",
    "    #     - num_guesses: the current number of guesses\n",
    "    #     - max_guesses: the maximum number of guesses allowed\n",
    "    #     - guess: the guessed word\n",
    "\n",
    "    #     Returns:\n",
    "    #     - the total reward for the current game state and action\n",
    "    #     \"\"\"\n",
    "    #     # Reward for guessing the mystery word correctly\n",
    "    #     if similarity_score == 100:\n",
    "    #         return 500\n",
    "\n",
    "    #     # Penalty for reaching the maximum number of guesses\n",
    "    #     if num_guesses >= max_guesses - 1:\n",
    "    #         return -100\n",
    "\n",
    "    #     # Reward based on the similarity score of the guess\n",
    "    #     similarity_reward = similarity_score * 2\n",
    "\n",
    "    #     # Penalty for making a duplicate guess\n",
    "    #     duplicate_penalty = -10 if guess in [gw[0] for gw in self.guessed_words[:-1]] else 0\n",
    "\n",
    "    #     # Penalty for taking more than the optimal number of guesses\n",
    "    #     optimal_guesses = math.ceil(math.log2(len(self.clusters))) + 1\n",
    "    #     inefficiency_penalty = -10 * (num_guesses - optimal_guesses) if num_guesses > optimal_guesses else 0\n",
    "\n",
    "    #     # Calculate the total reward\n",
    "    #     total_reward = similarity_reward + duplicate_penalty + inefficiency_penalty\n",
    "    #     return total_reward\n",
    "\n",
    "    def get_reward(self, similarity_score, num_guesses, max_guesses, guess, cluster):\n",
    "        \"\"\"\n",
    "        Calculate the reward for the current game state and action.\n",
    "\n",
    "        Parameters:\n",
    "        - similarity_score: the similarity score between the guessed word and the mystery word\n",
    "        - num_guesses: the current number of guesses\n",
    "        - max_guesses: the maximum number of guesses allowed\n",
    "        - guess: the guessed word\n",
    "\n",
    "        Returns:\n",
    "        - the total reward for the current game state and action\n",
    "        \"\"\"\n",
    "        # Reward for guessing the mystery word correctly\n",
    "        if similarity_score == 100:\n",
    "            return 250\n",
    "\n",
    "        # Penalty for reaching the maximum number of guesses\n",
    "        if num_guesses >= max_guesses - 1:\n",
    "            return -100\n",
    "\n",
    "        #Reward for picking right cluster\n",
    "        if self.mystery_word in cluster:\n",
    "            clusterReward = 200\n",
    "        else:\n",
    "            clusterReward = -200\n",
    "\n",
    "        # Penalty for taking more than the optimal number of guesses\n",
    "        optimal_guesses = math.ceil(math.log2(len(self.clusters))) + 1\n",
    "        inefficiency_penalty = -10 * (num_guesses - optimal_guesses) if num_guesses > optimal_guesses else 0\n",
    "\n",
    "        # Calculate the total reward\n",
    "        total_reward = clusterReward + inefficiency_penalty\n",
    "        return total_reward\n",
    "\n",
    "    def get_state(self):\n",
    "        \"\"\"\n",
    "        Get the current game state.\n",
    "\n",
    "        Returns:\n",
    "        - a list representing the current game state\n",
    "        \"\"\"\n",
    "        return self.state\n",
    "    def get_sub_state(self, clusterNum):\n",
    "        return self.sub_state[clusterNum]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAgent:\n",
    "    def __init__(self, num_clusters, num_bins, learning_rate, discount_rate, epsilon_decay):\n",
    "        self.epsilon = 1\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_rate = discount_rate\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.num_bins = num_bins\n",
    "        self.num_clusters = num_clusters\n",
    "        self.q_table = self.initialize_q_table()\n",
    "\n",
    "    def initialize_q_table(self):\n",
    "        \"\"\"\n",
    "        Initialize the Q-table for the agent with all zeros.\n",
    "\n",
    "        Returns:\n",
    "        - a dictionary representing the Q-table\n",
    "        \"\"\"\n",
    "        q_table = {}\n",
    "        for a in range(self.num_bins):\n",
    "            for b in range(self.num_bins):\n",
    "                for c in range(self.num_bins):\n",
    "                    for d in range(self.num_bins):\n",
    "                        state = (a, b, c, d)\n",
    "                        q_table[state] = [0] * self.num_clusters\n",
    "        return q_table\n",
    "      \n",
    "    def choose_action(self, state):\n",
    "        if np.random.uniform(0, 1) < self.epsilon:\n",
    "            action = np.random.randint(0, self.num_clusters)\n",
    "        else:\n",
    "            action = np.argmax(self.q_table[state])\n",
    "        return action\n",
    "\n",
    "    def update_q_table(self, state, action, reward, next_state):\n",
    "        \"\"\"\n",
    "        Update the Q-table using the Q-learning algorithm.\n",
    "\n",
    "        Parameters:\n",
    "        - state: the current state of the game\n",
    "        - action: the chosen action for the current state\n",
    "        - reward: the reward obtained for the current state and action\n",
    "        - next_state: the next state of the game after taking the chosen action\n",
    "        \"\"\"\n",
    "        current_q = self.q_table[state][action]\n",
    "        max_next_q = np.max(self.q_table[next_state])\n",
    "        new_q = current_q + self.learning_rate * (reward + self.discount_rate * max_next_q - current_q)\n",
    "        self.q_table[state][action] = new_q\n",
    "\n",
    "    def decay_epsilon(self, game_num):\n",
    "        self.epsilon = self.epsilon * np.exp(-self.epsilon_decay * game_num)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weight_init(m):\n",
    "\tif isinstance(m, nn.Linear):\n",
    "\t\tnn.init.xavier_uniform_(m.weight)\n",
    "\t\tnn.init.constant_(m.bias, 0.)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_word_from_cluster(cluster, guessed_words, similarity_threshold=30):\n",
    "    \"\"\"\n",
    "    This function chooses a word from a given cluster of unguessed words based on their similarity\n",
    "    to previously guessed words.\n",
    "\n",
    "    Parameters:\n",
    "    - cluster: a list of unguessed words\n",
    "    - guessed_words: a list of tuples, each containing a guessed word and its similarity score\n",
    "    - similarity_threshold: a threshold for the similarity score below which the function considers\n",
    "    the unguessed word not similar enough to the best guessed word\n",
    "\n",
    "    Returns:\n",
    "    - the chosen unguessed word from the cluster\n",
    "    \"\"\"\n",
    "\n",
    "    if not guessed_words:\n",
    "        # If no word has been guessed yet, choose randomly from the cluster\n",
    "        return random.choice(cluster)\n",
    "\n",
    "    # Get the best and worst guessed words and their similarity scores\n",
    "    best_guessed_word, best_similarity_score = guessed_words[0]\n",
    "    worst_guessed_word, worst_similarity_score = guessed_words[-1]\n",
    "\n",
    "    # Create a set of the guessed words for faster lookup\n",
    "    guessed_words_set = set([word for word, _ in guessed_words])\n",
    "\n",
    "    # Get unguessed words in the cluster\n",
    "    unguessed_words = [word for word in cluster if word not in guessed_words_set]\n",
    "\n",
    "    if not unguessed_words:\n",
    "        # If all words in the cluster have been guessed, choose from all words\n",
    "        unguessed_words = cluster\n",
    "    \n",
    "\n",
    "    # Get word vectors for unguessed words in the cluster\n",
    "    unguessed_vectors = np.array([gnews_model[word] for word in unguessed_words])\n",
    "\n",
    "    # Calculate similarity to the best and worst words\n",
    "    best_word_vec = gnews_model[best_guessed_word]\n",
    "    worst_word_vec = gnews_model[worst_guessed_word]\n",
    "\n",
    "    similarity_to_best = 100 * np.dot(unguessed_vectors, best_word_vec) / (np.linalg.norm(unguessed_vectors, axis=1) * np.linalg.norm(best_word_vec))\n",
    "    similarity_to_worst = 100 * np.dot(unguessed_vectors, worst_word_vec) / (np.linalg.norm(unguessed_vectors, axis=1) * np.linalg.norm(worst_word_vec))\n",
    "\n",
    "    adjusted_similarity = similarity_to_best - similarity_to_worst\n",
    "\n",
    "    # Get the index of the word with the highest adjusted similarity\n",
    "    best_index = np.argmax(adjusted_similarity)\n",
    "    return unguessed_words[best_index]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_word_from_cluster_rnn(cluster, guessed_words, model, similarity_threshold=30, target_word=None, optimizer=None):\n",
    "    \"\"\"\n",
    "    This function chooses a word from a given cluster of unguessed words based on their similarity\n",
    "    to previously guessed words.\n",
    "\n",
    "    Parameters:\n",
    "    - cluster: a list of unguessed words\n",
    "    - guessed_words: a list of tuples, each containing a guessed word and its similarity score\n",
    "\n",
    "    Returns:\n",
    "    - the chosen unguessed word from the cluster\n",
    "    \"\"\"\n",
    "\n",
    "    if not guessed_words:\n",
    "        # If no word has been guessed yet, choose randomly from the cluster\n",
    "        return random.choice(cluster)\n",
    "\n",
    "    # Get the best and worst guessed words and their similarity scores\n",
    "    best_guessed_word, best_similarity_score = guessed_words[0]\n",
    "    worst_guessed_word, worst_similarity_score = guessed_words[-1]\n",
    "\n",
    "    # Create a set of the guessed words for faster lookup\n",
    "    guessed_words_set = set([word for word, _ in guessed_words])\n",
    "\n",
    "    # Get unguessed words in the cluster\n",
    "    unguessed_words = [word for word in cluster if word not in guessed_words_set]\n",
    "\n",
    "    if not unguessed_words:\n",
    "        # If all words in the cluster have been guessed, choose from all words\n",
    "        unguessed_words = cluster\n",
    "\n",
    "    # Get word vectors for unguessed words in the cluster\n",
    "    unguessed_vectors = np.array([gnews_model[word] for word in unguessed_words])\n",
    "\n",
    "    # Calculate similarity to the best and worst words\n",
    "    best_word_vec = gnews_model[best_guessed_word]\n",
    "    worst_word_vec = gnews_model[worst_guessed_word]\n",
    "\n",
    "    similarity_to_best = 100 * np.dot(unguessed_vectors, best_word_vec) / (np.linalg.norm(unguessed_vectors, axis=1) * np.linalg.norm(best_word_vec))\n",
    "    similarity_to_worst = 100 * np.dot(unguessed_vectors, worst_word_vec) / (np.linalg.norm(unguessed_vectors, axis=1) * np.linalg.norm(worst_word_vec))\n",
    "\n",
    "    \n",
    "    adjusted_similarity = similarity_to_best - similarity_to_worst\n",
    "\n",
    "    # Get the index of the word with the highest adjusted similarity\n",
    "    # best_index = np.argmax(adjusted_similarity)\n",
    "    # return unguessed_words[best_index]\n",
    "    top_indices = np.argsort(adjusted_similarity)[-5:][::-1]\n",
    "    top_unguessed_vecs = unguessed_vectors[top_indices]\n",
    "    top_unguessed_vecs_tensor = torch.tensor(unguessed_vectors[top_indices])\n",
    "\n",
    "    guessed_vectors = torch.tensor(np.array([gnews_model[word] for word, _ in guessed_words]))\n",
    "    guessed_scores = torch.tensor(np.array([[score] for _, score in guessed_words]))\n",
    "\n",
    "\n",
    "    prev_5_guesses = torch.cat((guessed_vectors, guessed_scores), dim=1)[:5]\n",
    "\n",
    "    # append 0 to the end of each unguessed vector\n",
    "    A = torch.cat((top_unguessed_vecs_tensor, torch.zeros((top_unguessed_vecs_tensor.size(0), 1))), dim=1)\n",
    "    B = prev_5_guesses\n",
    "\n",
    "    # Reshape tensor A to have an additional dimension\n",
    "    reshaped_A = A.unsqueeze(1)  # Shape: (x, 1, 301)\n",
    "\n",
    "    # Repeat tensor B along the first dimension to match the number of sublists in A\n",
    "    repeated_B = B.unsqueeze(0).repeat(reshaped_A.size()[0], 1, 1)  # Shape: (x, y, 301)\n",
    "\n",
    "    # Concatenate tensors B and A along the second dimension\n",
    "    model_input = torch.cat((repeated_B, reshaped_A), dim=1).float()  # Shape: (x, y+1, 301)\n",
    "\n",
    "    model_output = model(model_input)\n",
    "    best_index = torch.argmax(model_output)\n",
    "    if target_word is not None:\n",
    "        target_vec = gnews_model[target_word]\n",
    "        target_word_similarity = torch.tensor(np.dot(top_unguessed_vecs, target_vec) / (np.linalg.norm(top_unguessed_vecs, axis=1) * np.linalg.norm(target_vec)))\n",
    "        optimizer.zero_grad()\n",
    "        loss = model.compute_loss(model_output, target_word_similarity.unsqueeze(1))\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "        return unguessed_words[top_indices[best_index]]\n",
    "\n",
    "    \n",
    "    return unguessed_words[top_indices[best_index]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Number: 0\n",
      "Top agent accuracy: 0%\n",
      "Sub-agent accuracies: [0, 0, 0, 0]\n",
      "Game Number: 100\n",
      "Num of games won in games 0 through 100 is 60 in an average of 27.783333333333335 moves with a max of 50 moves\n",
      "time per round: 0.059901490211486816\n",
      "Cumulative game win percentage: 0.6\n",
      "Top agent accuracy: 36.51%\n",
      "Sub-agent accuracies: [29.34, 26.09, 32.12, 25.75]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[33], line 68\u001b[0m\n\u001b[1;32m     65\u001b[0m sub_q_agent \u001b[39m=\u001b[39m sub_q_agents[top_action]\n\u001b[1;32m     66\u001b[0m sub_action \u001b[39m=\u001b[39m sub_q_agent\u001b[39m.\u001b[39mchoose_action(sub_state)\n\u001b[0;32m---> 68\u001b[0m word \u001b[39m=\u001b[39m choose_word_from_cluster(env\u001b[39m.\u001b[39;49mclusters[top_action][sub_action], env\u001b[39m.\u001b[39;49mguessed_words)\n\u001b[1;32m     69\u001b[0m similarity_score \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mguess_word(word, top_action, sub_action)\n\u001b[1;32m     71\u001b[0m next_state \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(env\u001b[39m.\u001b[39mget_state())\n",
      "Cell \u001b[0;32mIn[10], line 36\u001b[0m, in \u001b[0;36mchoose_word_from_cluster\u001b[0;34m(cluster, guessed_words, similarity_threshold)\u001b[0m\n\u001b[1;32m     32\u001b[0m     unguessed_words \u001b[39m=\u001b[39m cluster\n\u001b[1;32m     35\u001b[0m \u001b[39m# Get word vectors for unguessed words in the cluster\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m unguessed_vectors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([gnews_model[word] \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m unguessed_words])\n\u001b[1;32m     38\u001b[0m \u001b[39m# Calculate similarity to the best and worst words\u001b[39;00m\n\u001b[1;32m     39\u001b[0m best_word_vec \u001b[39m=\u001b[39m gnews_model[best_guessed_word]\n",
      "Cell \u001b[0;32mIn[10], line 36\u001b[0m, in \u001b[0;36m<listcomp>\u001b[0;34m(.0)\u001b[0m\n\u001b[1;32m     32\u001b[0m     unguessed_words \u001b[39m=\u001b[39m cluster\n\u001b[1;32m     35\u001b[0m \u001b[39m# Get word vectors for unguessed words in the cluster\u001b[39;00m\n\u001b[0;32m---> 36\u001b[0m unguessed_vectors \u001b[39m=\u001b[39m np\u001b[39m.\u001b[39marray([gnews_model[word] \u001b[39mfor\u001b[39;00m word \u001b[39min\u001b[39;00m unguessed_words])\n\u001b[1;32m     38\u001b[0m \u001b[39m# Calculate similarity to the best and worst words\u001b[39;00m\n\u001b[1;32m     39\u001b[0m best_word_vec \u001b[39m=\u001b[39m gnews_model[best_guessed_word]\n",
      "File \u001b[0;32m~/courses/4701/ai-semantle/.venv/lib/python3.9/site-packages/gensim/models/keyedvectors.py:403\u001b[0m, in \u001b[0;36mKeyedVectors.__getitem__\u001b[0;34m(self, key_or_keys)\u001b[0m\n\u001b[1;32m    389\u001b[0m \u001b[39m\u001b[39m\u001b[39m\"\"\"Get vector representation of `key_or_keys`.\u001b[39;00m\n\u001b[1;32m    390\u001b[0m \n\u001b[1;32m    391\u001b[0m \u001b[39mParameters\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    400\u001b[0m \n\u001b[1;32m    401\u001b[0m \u001b[39m\"\"\"\u001b[39;00m\n\u001b[1;32m    402\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39misinstance\u001b[39m(key_or_keys, _KEY_TYPES):\n\u001b[0;32m--> 403\u001b[0m     \u001b[39mreturn\u001b[39;00m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mget_vector(key_or_keys)\n\u001b[1;32m    405\u001b[0m \u001b[39mreturn\u001b[39;00m vstack([\u001b[39mself\u001b[39m\u001b[39m.\u001b[39mget_vector(key) \u001b[39mfor\u001b[39;00m key \u001b[39min\u001b[39;00m key_or_keys])\n",
      "File \u001b[0;32m~/courses/4701/ai-semantle/.venv/lib/python3.9/site-packages/gensim/models/keyedvectors.py:453\u001b[0m, in \u001b[0;36mKeyedVectors.get_vector\u001b[0;34m(self, key, norm)\u001b[0m\n\u001b[1;32m    450\u001b[0m \u001b[39melse\u001b[39;00m:\n\u001b[1;32m    451\u001b[0m     result \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mvectors[index]\n\u001b[0;32m--> 453\u001b[0m result\u001b[39m.\u001b[39;49msetflags(write\u001b[39m=\u001b[39;49m\u001b[39mFalse\u001b[39;49;00m)  \u001b[39m# disallow direct tampering that would invalidate `norms` etc\u001b[39;00m\n\u001b[1;32m    454\u001b[0m \u001b[39mreturn\u001b[39;00m result\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# RUN THIS CODE BLOCK FOR TESTING WITH GREEDY HEURISTIC\n",
    "\n",
    "from clusters import clusters\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "NUM_CLUSTERS = len(clusters)\n",
    "NUM_SUBCLUSTERS = len(secondLevelClusters[0])\n",
    "NUM_BINS = 5\n",
    "LEARNING_RATE = 0.01\n",
    "DISCOUNT_RATE = 0.90\n",
    "EPSILON_DECAY = 0.001\n",
    "NUM_GAMES = 3000\n",
    "MAX_GUESSES = 50\n",
    "\n",
    "# Initialize environment and agent\n",
    "mystery_word = answers[random.randint(0, len(answers) - 1)]\n",
    "env = Environment(mystery_word, secondLevelClusters)\n",
    "top_q_agent = QAgent(NUM_CLUSTERS, NUM_BINS, LEARNING_RATE, DISCOUNT_RATE, EPSILON_DECAY)\n",
    "sub_q_agents = [QAgent(NUM_SUBCLUSTERS, NUM_BINS, LEARNING_RATE, DISCOUNT_RATE, EPSILON_DECAY) for _ in range(NUM_CLUSTERS)]\n",
    "top_agent_attempts = 0\n",
    "top_agent_successes = 0\n",
    "sub_agent_attempts = [0] * NUM_CLUSTERS\n",
    "sub_agent_successes = [0] * NUM_CLUSTERS\n",
    "# Initialize game statistics\n",
    "game_wins = 0\n",
    "total_moves = 0\n",
    "similarity_score = 0\n",
    "\n",
    "game_nums = []\n",
    "win_percents = []\n",
    "start_time = time.time()\n",
    "# Run games\n",
    "for game_num in range(NUM_GAMES):\n",
    "    game_start_time = time.time()\n",
    "\n",
    "    if game_num % 100 == 0:\n",
    "        print(f\"Game Number: {game_num}\")\n",
    "        game_nums.append(game_num)\n",
    "        if game_wins:\n",
    "            print(f\"Num of games won in games {game_num - 100} through {game_num} is {game_wins} in an average of {total_moves/game_wins} moves with a max of {MAX_GUESSES} moves\")\n",
    "            win_percents.append(game_wins / 100)\n",
    "            print(f\"time per round: {(time.time() - start_time) / game_num}\")\n",
    "            print(f\"Cumulative game win percentage: {np.average(win_percents[1:])}\")\n",
    "        else:\n",
    "            win_percents.append(0)\n",
    "        game_wins = 0\n",
    "        total_moves = 0\n",
    "        top_agent_accuracy = round(top_agent_successes / top_agent_attempts * 100, 2) if top_agent_attempts != 0 else 0\n",
    "        sub_agent_accuracy = [round(sub_agent_successes[i] / sub_agent_attempts[i] * 100, 2) if sub_agent_attempts[i] != 0 else 0 for i in range(NUM_CLUSTERS)]\n",
    "        print(f\"Top agent accuracy: {top_agent_accuracy}%\")\n",
    "        print(f\"Sub-agent accuracies: {sub_agent_accuracy}\")\n",
    "        top_agent_attempts = 0\n",
    "        top_agent_successes = 0\n",
    "        sub_agent_attempts = [0] * NUM_CLUSTERS\n",
    "        sub_agent_successes = [0] * NUM_CLUSTERS\n",
    "    state = tuple(env.get_state())\n",
    "    mystery_word = answers[random.randint(0, len(answers) - 1)]\n",
    "    env.mystery_word = mystery_word\n",
    "\n",
    "    for guess in range(MAX_GUESSES):\n",
    "        if similarity_score != 100:\n",
    "            top_action = top_q_agent.choose_action(state)\n",
    "            sub_state = tuple(env.get_sub_state(top_action))\n",
    "            sub_q_agent = sub_q_agents[top_action]\n",
    "            sub_action = sub_q_agent.choose_action(sub_state)\n",
    "\n",
    "            word = choose_word_from_cluster(env.clusters[top_action][sub_action], env.guessed_words)\n",
    "            similarity_score = env.guess_word(word, top_action, sub_action)\n",
    "\n",
    "            next_state = tuple(env.get_state())\n",
    "            next_sub_state = tuple(env.get_sub_state(top_action))\n",
    "            top_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word, clusters[top_action])\n",
    "            #top_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word)\n",
    "            top_q_agent.update_q_table(state, top_action, top_reward, next_state)\n",
    "            sub_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word, secondLevelClusters[top_action][sub_action])\n",
    "            #sub_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word)\n",
    "            sub_q_agent.update_q_table(sub_state, sub_action, sub_reward, next_sub_state)\n",
    "            top_agent_attempts += 1\n",
    "            if mystery_word in clusters[top_action]:\n",
    "                top_agent_successes += 1\n",
    "                sub_agent_attempts[top_action] += 1\n",
    "                if mystery_word in secondLevelClusters[top_action][sub_action]:\n",
    "                    sub_agent_successes[top_action] += 1\n",
    "            state = next_state\n",
    "            sub_state = next_sub_state\n",
    "        else:\n",
    "            #top_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word)\n",
    "            top_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word, clusters[top_action])\n",
    "            sub_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word, secondLevelClusters[sub_action])\n",
    "            #sub_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word)\n",
    "            top_q_agent.update_q_table(state, top_action, top_reward, next_state)\n",
    "            sub_q_agent.update_q_table(sub_state, sub_action, sub_reward, next_sub_state)\n",
    "            game_wins += 1\n",
    "            total_moves += guess\n",
    "            similarity_score = 0\n",
    "            break\n",
    "    env.guessed_words = []\n",
    "    top_q_agent.decay_epsilon(game_num)\n",
    "    sub_q_agent.decay_epsilon(game_num/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Number: 0\n",
      "Top agent accuracy: 0%\n",
      "Sub-agent accuracies: [0, 0, 0, 0]\n",
      "Game Number: 100\n",
      "Num of games won in games 0 through 100 is 45 in an average of 28.822222222222223 moves with a max of 50 moves\n",
      "Cumulative time per round: 0.22368453979492187\n",
      "Cumulative game win percentage: 0.45\n",
      "Top agent accuracy: 38.25%\n",
      "Sub-agent accuracies: [26.17, 19.56, 27.99, 24.88]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[32], line 69\u001b[0m\n\u001b[1;32m     66\u001b[0m sub_q_agent \u001b[39m=\u001b[39m sub_q_agents[top_action]\n\u001b[1;32m     67\u001b[0m sub_action \u001b[39m=\u001b[39m sub_q_agent\u001b[39m.\u001b[39mchoose_action(sub_state)\n\u001b[0;32m---> 69\u001b[0m word \u001b[39m=\u001b[39m choose_word_from_cluster_rnn(env\u001b[39m.\u001b[39;49mclusters[top_action][sub_action], env\u001b[39m.\u001b[39;49mguessed_words, model)\n\u001b[1;32m     70\u001b[0m similarity_score \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mguess_word(word, top_action, sub_action)\n\u001b[1;32m     72\u001b[0m next_state \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(env\u001b[39m.\u001b[39mget_state())\n",
      "Cell \u001b[0;32mIn[30], line 71\u001b[0m, in \u001b[0;36mchoose_word_from_cluster_rnn\u001b[0;34m(cluster, guessed_words, model, similarity_threshold, target_word, optimizer)\u001b[0m\n\u001b[1;32m     68\u001b[0m \u001b[39m# Concatenate tensors B and A along the second dimension\u001b[39;00m\n\u001b[1;32m     69\u001b[0m model_input \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((repeated_B, reshaped_A), dim\u001b[39m=\u001b[39m\u001b[39m1\u001b[39m)\u001b[39m.\u001b[39mfloat()  \u001b[39m# Shape: (x, y+1, 301)\u001b[39;00m\n\u001b[0;32m---> 71\u001b[0m model_output \u001b[39m=\u001b[39m model(model_input)\n\u001b[1;32m     72\u001b[0m best_index \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39margmax(model_output)\n\u001b[1;32m     73\u001b[0m \u001b[39mif\u001b[39;00m target_word \u001b[39mis\u001b[39;00m \u001b[39mnot\u001b[39;00m \u001b[39mNone\u001b[39;00m:\n",
      "File \u001b[0;32m~/courses/4701/ai-semantle/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/courses/4701/ai-semantle/heuristicrnn.py:38\u001b[0m, in \u001b[0;36mRNN.forward\u001b[0;34m(self, inputs)\u001b[0m\n\u001b[1;32m     36\u001b[0m \u001b[39mfor\u001b[39;00m j \u001b[39min\u001b[39;00m \u001b[39mrange\u001b[39m(\u001b[39m1\u001b[39m, \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mnum_hidden_layers):\n\u001b[1;32m     37\u001b[0m     h_ij \u001b[39m=\u001b[39m all_h[j]\u001b[39m.\u001b[39mclone()\n\u001b[0;32m---> 38\u001b[0m     z_j \u001b[39m=\u001b[39m \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mU_same[j](h_ij) \u001b[39m+\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mU_transition[j](next_h)\n\u001b[1;32m     40\u001b[0m     next_h \u001b[39m=\u001b[39m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39mrelu(z_j)\n\u001b[1;32m     41\u001b[0m     all_h[j] \u001b[39m=\u001b[39m next_h\u001b[39m.\u001b[39mclone()\n",
      "File \u001b[0;32m~/courses/4701/ai-semantle/.venv/lib/python3.9/site-packages/torch/nn/modules/module.py:1501\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1496\u001b[0m \u001b[39m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1497\u001b[0m \u001b[39m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1498\u001b[0m \u001b[39mif\u001b[39;00m \u001b[39mnot\u001b[39;00m (\u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_backward_pre_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_hooks \u001b[39mor\u001b[39;00m \u001b[39mself\u001b[39m\u001b[39m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1499\u001b[0m         \u001b[39mor\u001b[39;00m _global_backward_pre_hooks \u001b[39mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1500\u001b[0m         \u001b[39mor\u001b[39;00m _global_forward_hooks \u001b[39mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1501\u001b[0m     \u001b[39mreturn\u001b[39;00m forward_call(\u001b[39m*\u001b[39;49margs, \u001b[39m*\u001b[39;49m\u001b[39m*\u001b[39;49mkwargs)\n\u001b[1;32m   1502\u001b[0m \u001b[39m# Do not call functions when jit is used\u001b[39;00m\n\u001b[1;32m   1503\u001b[0m full_backward_hooks, non_full_backward_hooks \u001b[39m=\u001b[39m [], []\n",
      "File \u001b[0;32m~/courses/4701/ai-semantle/.venv/lib/python3.9/site-packages/torch/nn/modules/linear.py:114\u001b[0m, in \u001b[0;36mLinear.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[39mdef\u001b[39;00m \u001b[39mforward\u001b[39m(\u001b[39mself\u001b[39m, \u001b[39minput\u001b[39m: Tensor) \u001b[39m-\u001b[39m\u001b[39m>\u001b[39m Tensor:\n\u001b[0;32m--> 114\u001b[0m     \u001b[39mreturn\u001b[39;00m F\u001b[39m.\u001b[39;49mlinear(\u001b[39minput\u001b[39;49m, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mweight, \u001b[39mself\u001b[39;49m\u001b[39m.\u001b[39;49mbias)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# RUN THIS CODE BLOCK FOR TESTING WITH RNN HEURISTIC\n",
    "\n",
    "from clusters import clusters\n",
    "import time\n",
    "\n",
    "# Configuration\n",
    "NUM_CLUSTERS = len(clusters)\n",
    "NUM_SUBCLUSTERS = len(secondLevelClusters[0])\n",
    "NUM_BINS = 5\n",
    "LEARNING_RATE = 0.01\n",
    "DISCOUNT_RATE = 0.90\n",
    "EPSILON_DECAY = 0.001\n",
    "NUM_GAMES = 3000\n",
    "MAX_GUESSES = 50\n",
    "\n",
    "model = heuristicrnn.RNN(301, 200, 1, 2)\n",
    "model.load_model(\"heuristic-model-qtrained\")\n",
    "\n",
    "# Initialize environment and agent\n",
    "mystery_word = answers[random.randint(0, len(answers) - 1)]\n",
    "env = Environment(mystery_word, secondLevelClusters)\n",
    "top_q_agent = QAgent(NUM_CLUSTERS, NUM_BINS, LEARNING_RATE, DISCOUNT_RATE, EPSILON_DECAY)\n",
    "sub_q_agents = [QAgent(NUM_SUBCLUSTERS, NUM_BINS, LEARNING_RATE, DISCOUNT_RATE, EPSILON_DECAY) for _ in range(NUM_CLUSTERS)]\n",
    "top_agent_attempts = 0\n",
    "top_agent_successes = 0\n",
    "sub_agent_attempts = [0] * NUM_CLUSTERS\n",
    "sub_agent_successes = [0] * NUM_CLUSTERS\n",
    "# Initialize game statistics\n",
    "game_wins = 0\n",
    "total_moves = 0\n",
    "similarity_score = 0\n",
    "\n",
    "rnn_win_percents = []\n",
    "start_time = time.time()\n",
    "# Run games\n",
    "for game_num in range(NUM_GAMES):\n",
    "    game_start_time = time.time()\n",
    "\n",
    "    if game_num % 100 == 0:\n",
    "        print(f\"Game Number: {game_num}\")\n",
    "        if game_wins:\n",
    "            print(f\"Num of games won in games {game_num - 100} through {game_num} is {game_wins} in an average of {total_moves/game_wins} moves with a max of {MAX_GUESSES} moves\")\n",
    "            rnn_win_percents.append(game_wins / 100)\n",
    "            print(f\"Cumulative time per round: {(time.time() - start_time) / game_num}\")\n",
    "            print(f\"Cumulative game win percentage: {np.average(rnn_win_percents[1:])}\")\n",
    "        else:\n",
    "            rnn_win_percents.append(0)\n",
    "        game_wins = 0\n",
    "        total_moves = 0\n",
    "        top_agent_accuracy = round(top_agent_successes / top_agent_attempts * 100, 2) if top_agent_attempts != 0 else 0\n",
    "        sub_agent_accuracy = [round(sub_agent_successes[i] / sub_agent_attempts[i] * 100, 2) if sub_agent_attempts[i] != 0 else 0 for i in range(NUM_CLUSTERS)]\n",
    "        print(f\"Top agent accuracy: {top_agent_accuracy}%\")\n",
    "        print(f\"Sub-agent accuracies: {sub_agent_accuracy}\")\n",
    "        top_agent_attempts = 0\n",
    "        top_agent_successes = 0\n",
    "        sub_agent_attempts = [0] * NUM_CLUSTERS\n",
    "        sub_agent_successes = [0] * NUM_CLUSTERS\n",
    "    state = tuple(env.get_state())\n",
    "    mystery_word = answers[random.randint(0, len(answers) - 1)]\n",
    "    env.mystery_word = mystery_word\n",
    "\n",
    "    for guess in range(MAX_GUESSES):\n",
    "        if similarity_score != 100:\n",
    "            top_action = top_q_agent.choose_action(state)\n",
    "            sub_state = tuple(env.get_sub_state(top_action))\n",
    "            sub_q_agent = sub_q_agents[top_action]\n",
    "            sub_action = sub_q_agent.choose_action(sub_state)\n",
    "\n",
    "            word = choose_word_from_cluster_rnn(env.clusters[top_action][sub_action], env.guessed_words, model)\n",
    "            similarity_score = env.guess_word(word, top_action, sub_action)\n",
    "\n",
    "            next_state = tuple(env.get_state())\n",
    "            next_sub_state = tuple(env.get_sub_state(top_action))\n",
    "            top_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word, clusters[top_action])\n",
    "            #top_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word)\n",
    "            top_q_agent.update_q_table(state, top_action, top_reward, next_state)\n",
    "            sub_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word, secondLevelClusters[top_action][sub_action])\n",
    "            #sub_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word)\n",
    "            sub_q_agent.update_q_table(sub_state, sub_action, sub_reward, next_sub_state)\n",
    "            top_agent_attempts += 1\n",
    "            if mystery_word in clusters[top_action]:\n",
    "                top_agent_successes += 1\n",
    "                sub_agent_attempts[top_action] += 1\n",
    "                if mystery_word in secondLevelClusters[top_action][sub_action]:\n",
    "                    sub_agent_successes[top_action] += 1\n",
    "            state = next_state\n",
    "            sub_state = next_sub_state\n",
    "        else:\n",
    "            #top_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word)\n",
    "            top_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word, clusters[top_action])\n",
    "            sub_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word, secondLevelClusters[sub_action])\n",
    "            #sub_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word)\n",
    "            top_q_agent.update_q_table(state, top_action, top_reward, next_state)\n",
    "            sub_q_agent.update_q_table(sub_state, sub_action, sub_reward, next_sub_state)\n",
    "            game_wins += 1\n",
    "            total_moves += guess\n",
    "            similarity_score = 0\n",
    "            break\n",
    "    env.guessed_words = []\n",
    "    top_q_agent.decay_epsilon(game_num)\n",
    "    sub_q_agent.decay_epsilon(game_num/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Game Number: 0\n",
      "Top agent accuracy: 0%\n",
      "Sub-agent accuracies: [0, 0, 0, 0]\n",
      "Game Number: 100\n",
      "Num of games won in games 0 through 100 is 46 in an average of 30.97826086956522 moves with a max of 50 moves\n",
      "time per round: 2.474470360279083\n",
      "Top agent accuracy: 38.55%\n",
      "Sub-agent accuracies: [24.85, 24.56, 30.23, 24.75]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[31], line 64\u001b[0m\n\u001b[1;32m     61\u001b[0m sub_q_agent \u001b[39m=\u001b[39m sub_q_agents[top_action]\n\u001b[1;32m     62\u001b[0m sub_action \u001b[39m=\u001b[39m sub_q_agent\u001b[39m.\u001b[39mchoose_action(sub_state)\n\u001b[0;32m---> 64\u001b[0m word \u001b[39m=\u001b[39m choose_word_from_cluster_rnn(env\u001b[39m.\u001b[39;49mclusters[top_action][sub_action], env\u001b[39m.\u001b[39;49mguessed_words, model, optimizer\u001b[39m=\u001b[39;49moptimizer, target_word\u001b[39m=\u001b[39;49mmystery_word)\n\u001b[1;32m     65\u001b[0m similarity_score \u001b[39m=\u001b[39m env\u001b[39m.\u001b[39mguess_word(word, top_action, sub_action)\n\u001b[1;32m     67\u001b[0m next_state \u001b[39m=\u001b[39m \u001b[39mtuple\u001b[39m(env\u001b[39m.\u001b[39mget_state())\n",
      "Cell \u001b[0;32mIn[30], line 78\u001b[0m, in \u001b[0;36mchoose_word_from_cluster_rnn\u001b[0;34m(cluster, guessed_words, model, similarity_threshold, target_word, optimizer)\u001b[0m\n\u001b[1;32m     76\u001b[0m optimizer\u001b[39m.\u001b[39mzero_grad()\n\u001b[1;32m     77\u001b[0m loss \u001b[39m=\u001b[39m model\u001b[39m.\u001b[39mcompute_loss(model_output, target_word_similarity\u001b[39m.\u001b[39munsqueeze(\u001b[39m1\u001b[39m))\n\u001b[0;32m---> 78\u001b[0m loss\u001b[39m.\u001b[39;49mbackward()\n\u001b[1;32m     79\u001b[0m optimizer\u001b[39m.\u001b[39mstep()\n\u001b[1;32m     80\u001b[0m \u001b[39mreturn\u001b[39;00m unguessed_words[top_indices[best_index]]\n",
      "File \u001b[0;32m~/courses/4701/ai-semantle/.venv/lib/python3.9/site-packages/torch/_tensor.py:487\u001b[0m, in \u001b[0;36mTensor.backward\u001b[0;34m(self, gradient, retain_graph, create_graph, inputs)\u001b[0m\n\u001b[1;32m    477\u001b[0m \u001b[39mif\u001b[39;00m has_torch_function_unary(\u001b[39mself\u001b[39m):\n\u001b[1;32m    478\u001b[0m     \u001b[39mreturn\u001b[39;00m handle_torch_function(\n\u001b[1;32m    479\u001b[0m         Tensor\u001b[39m.\u001b[39mbackward,\n\u001b[1;32m    480\u001b[0m         (\u001b[39mself\u001b[39m,),\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m    485\u001b[0m         inputs\u001b[39m=\u001b[39minputs,\n\u001b[1;32m    486\u001b[0m     )\n\u001b[0;32m--> 487\u001b[0m torch\u001b[39m.\u001b[39;49mautograd\u001b[39m.\u001b[39;49mbackward(\n\u001b[1;32m    488\u001b[0m     \u001b[39mself\u001b[39;49m, gradient, retain_graph, create_graph, inputs\u001b[39m=\u001b[39;49minputs\n\u001b[1;32m    489\u001b[0m )\n",
      "File \u001b[0;32m~/courses/4701/ai-semantle/.venv/lib/python3.9/site-packages/torch/autograd/__init__.py:200\u001b[0m, in \u001b[0;36mbackward\u001b[0;34m(tensors, grad_tensors, retain_graph, create_graph, grad_variables, inputs)\u001b[0m\n\u001b[1;32m    195\u001b[0m     retain_graph \u001b[39m=\u001b[39m create_graph\n\u001b[1;32m    197\u001b[0m \u001b[39m# The reason we repeat same the comment below is that\u001b[39;00m\n\u001b[1;32m    198\u001b[0m \u001b[39m# some Python versions print out the first line of a multi-line function\u001b[39;00m\n\u001b[1;32m    199\u001b[0m \u001b[39m# calls in the traceback and some print out the last line\u001b[39;00m\n\u001b[0;32m--> 200\u001b[0m Variable\u001b[39m.\u001b[39;49m_execution_engine\u001b[39m.\u001b[39;49mrun_backward(  \u001b[39m# Calls into the C++ engine to run the backward pass\u001b[39;49;00m\n\u001b[1;32m    201\u001b[0m     tensors, grad_tensors_, retain_graph, create_graph, inputs,\n\u001b[1;32m    202\u001b[0m     allow_unreachable\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m, accumulate_grad\u001b[39m=\u001b[39;49m\u001b[39mTrue\u001b[39;49;00m)\n",
      "\u001b[0;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "# RUN THIS CODE BLOCK TO TRAIN RNN DURING Q-LEARNING\n",
    "\n",
    "from clusters import clusters\n",
    "\n",
    "# Configuration\n",
    "NUM_CLUSTERS = len(clusters)\n",
    "NUM_SUBCLUSTERS = len(secondLevelClusters[0])\n",
    "NUM_BINS = 5\n",
    "LEARNING_RATE = 0.01\n",
    "DISCOUNT_RATE = 0.90\n",
    "EPSILON_DECAY = 0.001\n",
    "NUM_GAMES = 3000\n",
    "MAX_GUESSES = 50\n",
    "\n",
    "\n",
    "# Initialize environment and agent\n",
    "mystery_word = answers[random.randint(0, len(answers) - 1)]\n",
    "env = Environment(mystery_word, secondLevelClusters)\n",
    "top_q_agent = QAgent(NUM_CLUSTERS, NUM_BINS, LEARNING_RATE, DISCOUNT_RATE, EPSILON_DECAY)\n",
    "sub_q_agents = [QAgent(NUM_SUBCLUSTERS, NUM_BINS, LEARNING_RATE, DISCOUNT_RATE, EPSILON_DECAY) for _ in range(NUM_CLUSTERS)]\n",
    "top_agent_attempts = 0\n",
    "top_agent_successes = 0\n",
    "sub_agent_attempts = [0] * NUM_CLUSTERS\n",
    "sub_agent_successes = [0] * NUM_CLUSTERS\n",
    "# Initialize game statistics\n",
    "game_wins = 0\n",
    "total_moves = 0\n",
    "similarity_score = 0\n",
    "\n",
    "model = heuristicrnn.RNN(301, 200, 1, 2)\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=.01)\n",
    "\n",
    "# Run games\n",
    "for game_num in range(NUM_GAMES):\n",
    "    model.train()\n",
    "\n",
    "    if game_num % 100 == 0:\n",
    "        print(f\"Game Number: {game_num}\")\n",
    "        if game_wins:\n",
    "            print(f\"Num of games won in games {game_num - 100} through {game_num} is {game_wins} in an average of {total_moves/game_wins} moves with a max of {MAX_GUESSES} moves\")\n",
    "            print(f\"time per round: {(time.time() - start_time) / game_num}\")\n",
    "\n",
    "        game_wins = 0\n",
    "        total_moves = 0\n",
    "        top_agent_accuracy = round(top_agent_successes / top_agent_attempts * 100, 2) if top_agent_attempts != 0 else 0\n",
    "        sub_agent_accuracy = [round(sub_agent_successes[i] / sub_agent_attempts[i] * 100, 2) if sub_agent_attempts[i] != 0 else 0 for i in range(NUM_CLUSTERS)]\n",
    "        print(f\"Top agent accuracy: {top_agent_accuracy}%\")\n",
    "        print(f\"Sub-agent accuracies: {sub_agent_accuracy}\")\n",
    "        top_agent_attempts = 0\n",
    "        top_agent_successes = 0\n",
    "        sub_agent_attempts = [0] * NUM_CLUSTERS\n",
    "        sub_agent_successes = [0] * NUM_CLUSTERS\n",
    "    state = tuple(env.get_state())\n",
    "    mystery_word = answers[random.randint(0, len(answers) - 1)]\n",
    "    env.mystery_word = mystery_word\n",
    "\n",
    "    for guess in range(MAX_GUESSES):\n",
    "        if similarity_score != 100:\n",
    "            top_action = top_q_agent.choose_action(state)\n",
    "            sub_state = tuple(env.get_sub_state(top_action))\n",
    "            sub_q_agent = sub_q_agents[top_action]\n",
    "            sub_action = sub_q_agent.choose_action(sub_state)\n",
    "\n",
    "            word = choose_word_from_cluster_rnn(env.clusters[top_action][sub_action], env.guessed_words, model, optimizer=optimizer, target_word=mystery_word)\n",
    "            similarity_score = env.guess_word(word, top_action, sub_action)\n",
    "\n",
    "            next_state = tuple(env.get_state())\n",
    "            next_sub_state = tuple(env.get_sub_state(top_action))\n",
    "            top_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word, clusters[top_action])\n",
    "            #top_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word)\n",
    "            top_q_agent.update_q_table(state, top_action, top_reward, next_state)\n",
    "            sub_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word, secondLevelClusters[top_action][sub_action])\n",
    "            #sub_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word)\n",
    "            sub_q_agent.update_q_table(sub_state, sub_action, sub_reward, next_sub_state)\n",
    "            top_agent_attempts += 1\n",
    "            if mystery_word in clusters[top_action]:\n",
    "                top_agent_successes += 1\n",
    "                sub_agent_attempts[top_action] += 1\n",
    "                if mystery_word in secondLevelClusters[top_action][sub_action]:\n",
    "                    sub_agent_successes[top_action] += 1\n",
    "            state = next_state\n",
    "            sub_state = next_sub_state\n",
    "        else:\n",
    "            #top_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word)\n",
    "            top_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word, clusters[top_action])\n",
    "            sub_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word, secondLevelClusters[sub_action])\n",
    "            #sub_reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word)\n",
    "            top_q_agent.update_q_table(state, top_action, top_reward, next_state)\n",
    "            sub_q_agent.update_q_table(sub_state, sub_action, sub_reward, next_sub_state)\n",
    "            game_wins += 1\n",
    "            total_moves += guess\n",
    "            similarity_score = 0\n",
    "            break\n",
    "\n",
    "\n",
    "    env.guessed_words = []\n",
    "    top_q_agent.decay_epsilon(game_num)\n",
    "    sub_q_agent.decay_epsilon(game_num/4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Save model after training it\n",
    "model.save_model(\"heuristic-model-qtrained\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "# Plotting the graph\n",
    "plt.plot(game_nums, win_percents, marker='o', label=\"Greedy Word Selection\")\n",
    "plt.plot(game_nums, rnn_win_percents, marker='o', label=\"Neural Network Word Selection\")\n",
    "\n",
    "# Adding labels and title\n",
    "plt.xlabel('Game Number')\n",
    "plt.ylabel('Win Percentage')\n",
    "plt.title('Win Percentage by Game')\n",
    "\n",
    "plt.ylim(0, 1)\n",
    "\n",
    "plt.legend()\n",
    "\n",
    "# Displaying the graph\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "4\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'q_agent' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[13], line 56\u001b[0m\n\u001b[1;32m     54\u001b[0m game_loss \u001b[39m=\u001b[39m \u001b[39m0\u001b[39m\n\u001b[1;32m     55\u001b[0m \u001b[39mif\u001b[39;00m similarity_score \u001b[39m!=\u001b[39m \u001b[39m100\u001b[39m:\n\u001b[0;32m---> 56\u001b[0m     action \u001b[39m=\u001b[39m q_agent\u001b[39m.\u001b[39mchoose_action(state)\n\u001b[1;32m     57\u001b[0m     word, expected_out, model_output \u001b[39m=\u001b[39m choose_word_from_cluster_rnn(env\u001b[39m.\u001b[39mclusters[action], env\u001b[39m.\u001b[39mguessed_words, target_word\u001b[39m=\u001b[39mmystery_word)\n\u001b[1;32m     58\u001b[0m     game_expected_out \u001b[39m=\u001b[39m torch\u001b[39m.\u001b[39mcat((game_expected_out, expected_out), dim\u001b[39m=\u001b[39m\u001b[39m0\u001b[39m)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'q_agent' is not defined"
     ]
    }
   ],
   "source": [
    "from clusters import clusters\n",
    "import time\n",
    "# Configuration — .01 .90 .001 best parameters so far\n",
    "NUM_CLUSTERS = len(clusters)\n",
    "NUM_SUBCLUSTERS = len(secondLevelClusters[0])\n",
    "NUM_BINS = 5\n",
    "LEARNING_RATE = 0.01\n",
    "DISCOUNT_RATE = 0.90\n",
    "EPSILON_DECAY = 0.001\n",
    "NUM_GAMES = 10000\n",
    "MAX_GUESSES = 35\n",
    "\n",
    "# Initialize environment and agent\n",
    "mystery_word = answers[random.randint(0, len(answers) - 1)]\n",
    "env = Environment(mystery_word, clusters)\n",
    "agents = [QAgent(NUM_SUBCLUSTERS, NUM_BINS, LEARNING_RATE, DISCOUNT_RATE, EPSILON_DECAY) for _ in range(NUM_CLUSTERS)]\n",
    "\n",
    "# Initialize game statistics\n",
    "game_wins = 0\n",
    "total_moves = 0\n",
    "similarity_score = 0\n",
    "\n",
    "cumulative_game_wins = 0\n",
    "\n",
    "optimizer = optim.AdamW(model.parameters(), lr=0.001, weight_decay=.01)\n",
    "start_time = time.time()\n",
    "\n",
    "# Run games\n",
    "for game_num in range(NUM_GAMES):\n",
    "    total_loss = 0\n",
    "\n",
    "    if game_num % 100 == 0:\n",
    "        if game_wins:\n",
    "            print(f\"Num of games won in games {game_num - 100} through {game_num} is {game_wins} in an average of {total_moves/game_wins} moves with a max of {MAX_GUESSES} moves\")\n",
    "            cumulative_game_wins += game_wins\n",
    "            print(f\"Total number of games won through {game_num} is {cumulative_game_wins}\")\n",
    "            print(f\"Average time per game: {(time.time() - start_time) / game_num}\")\n",
    "\n",
    "\n",
    "        game_wins = 0\n",
    "        total_moves = 0\n",
    "\n",
    "\n",
    "    state = tuple(env.get_state())\n",
    "    mystery_word = answers[random.randint(0, len(answers) - 1)]\n",
    "    env.mystery_word = mystery_word\n",
    "\n",
    "    # Vectors for each expected/model output for loss calculation\n",
    "    game_expected_out = torch.tensor([], requires_grad=True)\n",
    "    game_model_output = torch.tensor([], requires_grad=True)\n",
    "\n",
    "    for guess in range(MAX_GUESSES):\n",
    "        game_loss = 0\n",
    "        if similarity_score != 100:\n",
    "            action = q_agent.choose_action(state)\n",
    "            word, expected_out, model_output = choose_word_from_cluster_rnn(env.clusters[action], env.guessed_words, target_word=mystery_word)\n",
    "            game_expected_out = torch.cat((game_expected_out, expected_out), dim=0)\n",
    "            game_model_output = torch.cat((game_model_output, model_output), dim=0)\n",
    "\n",
    "            similarity_score = env.guess_word(word, action)\n",
    "\n",
    "            next_state = tuple(env.get_state())\n",
    "            reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word)\n",
    "            q_agent.update_q_table(state, action, reward, next_state)\n",
    "            state = next_state\n",
    "            game_loss += loss\n",
    "            total_loss += loss\n",
    "        else:\n",
    "            reward = env.get_reward(similarity_score, guess, MAX_GUESSES, word)\n",
    "            q_agent.update_q_table(state, action, reward, next_state)\n",
    "            game_wins += 1\n",
    "            total_moves += guess\n",
    "            similarity_score = 0\n",
    "            break\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "    loss = model.compute_loss(game_expected_out, game_model_output)\n",
    "    loss.backward()\n",
    "    optimizer.step()\n",
    "\n",
    "\n",
    "\n",
    "    env.guessed_words = []\n",
    "    q_agent.decay_epsilon(game_num)\n",
    "\n",
    "if game_wins:\n",
    "    print(f\"Num of games won in games {game_num - 10000} through {game_num} is {game_wins} in an average of {total_moves/game_wins} moves with a max of {MAX_GUESSES} moves\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.2"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "508433ef1a748df743d3eed77eb62640714056f18aabece65e35e225b1c5b18a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
