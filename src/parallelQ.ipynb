{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import bisect \n",
    "import math\n",
    "import random \n",
    "import gensim\n",
    "from answers import secretWords as answers\n",
    "from constants import PATH_TO_DATASET\n",
    "import concurrent.futures\n",
    "from multiprocessing import Manager\n",
    "gnews_model = gensim.models.KeyedVectors.load_word2vec_format(PATH_TO_DATASET, binary=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "class environment:\n",
    "    def __init__(self, mystery_word, clusters):\n",
    "        self.mystery_word = mystery_word\n",
    "        self.clusters = clusters\n",
    "        self.guessed_words = []\n",
    "        self.state = [0] * len(clusters)\n",
    "        self.previous_state = [0] * len(clusters)\n",
    "\n",
    "    def binSimilarityScore(self, similarityScore):\n",
    "        bins = [0, 10, 25, 50]\n",
    "        return bisect.bisect_left(bins, similarityScore)\n",
    "\n",
    "    def guess_word(self, word, clusterNumber):\n",
    "        if word == self.mystery_word:\n",
    "            return 100\n",
    "        similarity_score = round(100 * gnews_model.similarity(word, self.mystery_word), 6)\n",
    "        self.guessed_words.append((word, similarity_score))\n",
    "        self.guessed_words = sorted(self.guessed_words, key=lambda x: x[1], reverse=True)\n",
    "        binned_score = self.binSimilarityScore(similarity_score)\n",
    "        self.previous_state = self.state.copy()\n",
    "        self.state[clusterNumber] = binned_score\n",
    "        return similarity_score\n",
    "\n",
    "    def get_reward(self, similarity_score, num_guesses, max_guesses, guess):\n",
    "        if similarity_score == 100:\n",
    "            return 500\n",
    "\n",
    "        if num_guesses >= max_guesses - 1:\n",
    "            return -100\n",
    "\n",
    "        state_reward = sum(self.state) * 10\n",
    "        inefficiency_penalty = -10 * num_guesses\n",
    "        guess_reward = similarity_score\n",
    "\n",
    "        state_difference = sum(self.state) - sum(self.previous_state)\n",
    "        progress_bonus = 25 * state_difference if state_difference > 0 else 0\n",
    "\n",
    "        total_reward = (\n",
    "            state_reward\n",
    "            + inefficiency_penalty\n",
    "            + progress_bonus\n",
    "        )\n",
    "        return total_reward\n",
    "\n",
    "    def get_state(self):\n",
    "        return self.state\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class QAgent():\n",
    "    def __init__(self, num_clusters, num_bins, learning_rate, discount_rate, epsilon_decay, shared_q_table):\n",
    "        self.num_clusters = num_clusters\n",
    "        self.num_bins = num_bins\n",
    "        self.learning_rate = learning_rate\n",
    "        self.discount_rate = discount_rate\n",
    "        self.epsilon = 0.0001\n",
    "        self.epsilon_decay = epsilon_decay\n",
    "        self.q_table = shared_q_table\n",
    "\n",
    "    def choose_action(self, state):\n",
    "        if random.random() < self.epsilon:\n",
    "            return random.randint(0, self.num_clusters - 1)\n",
    "        else:\n",
    "            return np.argmax(self.q_table[state])\n",
    "    \n",
    "    def update(self, state, action, reward, next_state):\n",
    "        current_q = self.q_table[state][action]\n",
    "        max_next_q = np.max(self.q_table[next_state])\n",
    "        new_q = current_q + self.learning_rate * (reward + self.discount_rate * max_next_q - current_q)\n",
    "        self.q_table[state][action] = new_q\n",
    "    \n",
    "    def decayEpsilon(self, game_number):\n",
    "        self.epsilon = 0.01 + (0.5 - 0.01) * math.exp(-self.epsilon_decay * game_number)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def choose_word_from_cluster(cluster, guessed_words, similarity_threshold=30):\n",
    "    if not guessed_words:\n",
    "        return cluster[random.randint(0, len(cluster) - 1)]\n",
    "\n",
    "    best_word = guessed_words[0][0]\n",
    "    worst_word = guessed_words[-1][0]\n",
    "    best_similarity = guessed_words[0][1]\n",
    "\n",
    "    guessed_words_set = set([gw[0] for gw in guessed_words])\n",
    "\n",
    "    # Get unguessed words in the cluster\n",
    "    unguessed_words = [word for word in cluster if word not in guessed_words_set]\n",
    "\n",
    "    if not unguessed_words:\n",
    "        # If all words in the cluster have been guessed, choose from all words\n",
    "        unguessed_words = cluster\n",
    "\n",
    "    # Get word vectors for unguessed words in the cluster\n",
    "    unguessed_vectors = np.array([gnews_model[word] for word in unguessed_words])\n",
    "\n",
    "    # Calculate similarity to the best and worst words\n",
    "    best_word_vec = gnews_model[best_word]\n",
    "    worst_word_vec = gnews_model[worst_word]\n",
    "\n",
    "    similarity_to_best = np.dot(unguessed_vectors, best_word_vec) / (np.linalg.norm(unguessed_vectors, axis=1) * np.linalg.norm(best_word_vec))\n",
    "    similarity_to_worst = np.dot(unguessed_vectors, worst_word_vec) / (np.linalg.norm(unguessed_vectors, axis=1) * np.linalg.norm(worst_word_vec))\n",
    "\n",
    "    if best_similarity < similarity_threshold:\n",
    "        adjusted_similarity = (similarity_to_best + similarity_to_worst) / 2\n",
    "    else:\n",
    "        adjusted_similarity = similarity_to_best - similarity_to_worst\n",
    "\n",
    "    # Get the index of the word with the highest adjusted similarity\n",
    "    best_index = np.argmax(adjusted_similarity)\n",
    "\n",
    "    return unguessed_words[best_index]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0\n"
     ]
    }
   ],
   "source": [
    "from clusters import clusters\n",
    "from runSingle import run_single_game\n",
    "num_clusters = len(clusters)\n",
    "num_bins = 5\n",
    "learning_rate = 0.01\n",
    "discount_rate = 0.90\n",
    "epsilon_decay = 0.001\n",
    "similarity_score = 0\n",
    "\n",
    "num_games = 20000\n",
    "max_guesses = 35\n",
    "game_wins = 0\n",
    "total_moves = 0\n",
    "\n",
    "shared_q_table = {}\n",
    "\n",
    "for a in range(num_bins):\n",
    "    for b in range(num_bins):\n",
    "        for c in range(num_bins):\n",
    "            for d in range(num_bins):\n",
    "                tempState = (a, b, c, d)\n",
    "                shared_q_table[tempState] = [0] * num_clusters\n",
    "\n",
    "\n",
    "\n",
    "num_parallel_games = 8  # Set to the number of cores of CPU\n",
    "q_agent = QAgent(num_clusters, num_bins, learning_rate, discount_rate, epsilon_decay, shared_q_table)\n",
    "shared_q_table = {key: [0] * num_clusters for key in shared_q_table}  # Convert the shared_q_table to a regular dictionary\n",
    "\n",
    "import concurrent.futures\n",
    "import random\n",
    "from clusters import clusters\n",
    "\n",
    "with concurrent.futures.ProcessPoolExecutor(max_workers=num_parallel_games) as executor:\n",
    "    for num_game in range(0, num_games, num_parallel_games):\n",
    "        futures = []\n",
    "        print(num_game)\n",
    "        if(not game_wins == 0): print(\"Num of games won in games \" + str(num_game - 8) + \" through \" + str(num_game) + \" is \" + str(game_wins) + \" in an average of \" + str(total_moves/game_wins) + \" moves with a max of \" + str(max_guesses) + \" moves\");\n",
    "        game_wins = 0\n",
    "        total_moves = 0\n",
    "        mystery_words = [answers[random.randint(0, len(answers) - 1)] for _ in range(num_parallel_games)]\n",
    "        for i in range(num_parallel_games):\n",
    "            future = executor.submit(run_single_game, mystery_words[i], q_agent, max_guesses, shared_q_table)\n",
    "            futures.append(future)\n",
    "\n",
    "        for future in concurrent.futures.as_completed(futures):\n",
    "            game_win, total_move = future.result()\n",
    "            game_wins += game_win\n",
    "            total_moves += total_move\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "mystery_word = answers[random.randint(0, len(answers) - 1)]\n",
    "from clusters import clusters \n",
    "num_clusters = len(clusters)\n",
    "num_bins = 5\n",
    "learning_rate = 0.01\n",
    "discount_rate = 0.90\n",
    "epsilon_decay = 0.0025\n",
    "similarity_score = 0\n",
    "\n",
    "env = environment(mystery_word, clusters)\n",
    "q_agent = QAgent(num_clusters, num_bins, learning_rate, discount_rate, epsilon_decay)\n",
    "num_games = 20000\n",
    "max_guesses = 35\n",
    "game_wins = 0 \n",
    "total_moves = 0 \n",
    "\n",
    "    for i in range(max_guesses):\n",
    "        if similarity_score != 100:\n",
    "            action = q_agent.choose_action(state)\n",
    "            word = choose_word_from_cluster(env.clusters[action], env.guessed_words)\n",
    "            similarity_score = env.guess_word(word, action)\n",
    "            next_state = tuple(env.get_state())\n",
    "            reward = env.get_reward(similarity_score, i, max_guesses, word)\n",
    "            q_agent.update(state, action, reward, next_state)\n",
    "            state = next_state\n",
    "        else:\n",
    "            reward = env.get_reward(similarity_score, i, max_guesses, word)\n",
    "            q_agent.update(state, action, reward, next_state)\n",
    "            game_wins += 1\n",
    "            total_moves += i\n",
    "            similarity_score = 0\n",
    "            break\n",
    "    env.guessed_words = []\n",
    "    q_agent.decayEpsilon(num_game)\n",
    "if(not game_wins == 0): print(\"Num of games won in games \" + str(num_game - 10000) + \" through \" + str(num_game) + \" is \" + str(game_wins) + \" in an average of \" + str(total_moves/game_wins) + \" moves with a max of \" + str(max_guesses) + \" moves\");\n",
    "\n",
    "        \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "learning_rates = [0.03, 0.05, 0.1, 0.12, 0.15, 0.18]\n",
    "discount_rates = [0.85, 0.9, 0.95, 0.99]\n",
    "epsilon_decays = [0.08, 0.1, 0.12, 0.14, 0.16]\n",
    "\n",
    "num_games = 20000\n",
    "max_guesses = 50\n",
    "\n",
    "for learning_rate in learning_rates:\n",
    "    for discount_rate in discount_rates:\n",
    "        for epsilon_decay in epsilon_decays:\n",
    "            q_agent = QAgent(num_clusters, num_bins, learning_rate, discount_rate, epsilon_decay)\n",
    "            game_wins = 0\n",
    "            total_moves = 0\n",
    "\n",
    "            for num_game in range(num_games):\n",
    "                if(num_game % 20000 == 0):\n",
    "                    if(not game_wins == 0): print(\"Num of games won in games \" + str(num_game - 10000) + \" through \" + str(num_game) + \" is \" + str(game_wins) + \" in an average of \" + str(total_moves/game_wins) + \" moves with a max of \" + str(max_guesses) + \" moves\");\n",
    "                    game_wins = 0\n",
    "                    total_moves = 0\n",
    "                state = tuple(env.get_state())\n",
    "                mystery_word = answers[random.randint(0, len(answers) - 1)]\n",
    "\n",
    "                for i in range(max_guesses):\n",
    "                    if(similarity_score != 100):\n",
    "                        action = q_agent.choose_action(state)\n",
    "                        word = choose_word_from_cluster(env.clusters[action], env.guessed_words)\n",
    "                        similarity_score = env.guess_word(word, action)\n",
    "                        next_state = tuple(env.get_state())\n",
    "                        q_agent.update(state, action, math.log(np.max([0.01, similarity_score])), next_state)\n",
    "                        state = next_state\n",
    "                    else:\n",
    "                        game_wins += 1\n",
    "                        total_moves += i\n",
    "                        similarity_score = 0\n",
    "                        break\n",
    "\n",
    "                    env.guessed_words = []\n",
    "                    q_agent.decayEpsilon(num_game)\n",
    "\n",
    "            print(\"Parameters: learning_rate={}, discount_rate={}, epsilon_decay={}\".format(learning_rate, discount_rate, epsilon_decay))\n",
    "            print(\"Num of games won: {}, average moves per win: {}, max moves: {}\".format(game_wins, total_moves / game_wins if game_wins > 0 else 0, max_guesses))\n",
    "            print()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.10 64-bit",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.10"
  },
  "orig_nbformat": 4,
  "vscode": {
   "interpreter": {
    "hash": "508433ef1a748df743d3eed77eb62640714056f18aabece65e35e225b1c5b18a"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
